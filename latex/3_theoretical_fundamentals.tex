\subsection{Reachability Analysis}
The goal of reachability analysis is to compute the reach-avoid set (RAS) defined as the set of initial states from which the system, using an optimal input, can be driven to a target set within a finite time horizon and satisfying time-varying state constraints at all times. In a reachability problem formulation, the target set can represent a set of undesired states (unsafe), or a set of desired states, in the first case, the RAS contains states to avoid since there exists an optimal input (disturbance) that leads the state into an unsafe region. In the second case instead, the RAS represents safe states from which, applying an optimal input (control law), the system can reach a desired state. 
In the literature, the just described reach-avoid set, is also called backward reachable set (BRS), in alternative to it, in some cases one might be interested in computing a forward reachable set (FRS), defined as the set of all states that the system can reach from a given initial set of states after a finite time horizon. In order to understand the difference between BRS and FRS, consider a reachability problem in which the target set contains unsafe states, the FRS can be used to check whether the set of possible future states of the system includes undesired states, the BRS instead, can be used to compute, by starting from known unsafe conditions, those states that must be avoided. In this paper HJ-RA is used to compute the BRS of the system, however, it can be used also to compute the FRS. 
All systems in the real world are subject to a disturbance, hence they have two different kinds of inputs, a controllable one (control) and another uncontrollable (disturbance); for that reason the computation of the BRS can be formulated in terms of a two-player game. For example, consider an aircraft that has to follow a trajectory to complete a task, the system has two inputs: a control input (Player 1) and a disturbance (Player 2), in this scenario, the disturbance could be the wind. Suppose now that there is a goal position to reach (target set) along the trajectory, therefore the control input tries to bring the state at the target and the disturbance to steer it away, in this case, the BRS contains all the initial states for which exists an optimal control command that despite the worst disturbance, brings the system at the goal position. Suppose now instead of a goal, there is an obstacle along the trajectory, now the target set is defined by all states of the system that correspond to a collision with the obstacle, therefore, the BRS contains those states which could lead to a collision despite the best possible control actions. In both cases, the BRS can be computed by studying the outcome of the game between the two players, however those two games are “games of kind” due to the way they are formulated, namely games in which the outcome is binary: system reaches or not the target set. In order to solve this type of game it is necessary to translate it into a “games of degree” in which players want to optimize a cost function, the players have opposite goals, one tries to maximize and the other to minimize it. An approach we will see later, called Level Set Method, can perform this kind of transformation by translating the problem into a standard differential game.

\subsection{Differential Games}
%COSA E’ LOWER VALUE DEL GAME
To understand better the concept of differential games and how it is formulated, assume we are in the case in which we have a set to reach. In this case we want to reach with our control input (Player 1) the set of safe states of the reachable set; in other words Player 1 tries to bring the system towards the target with its input while in the meanwhile the disturbance (Player 2) tries to steer the system away the target with its input. To have a  more intuitive understanding of the inputs, consider that in our example the target set will represent the goal set in a pursuit-evasion game. Our evader (control input) will then be player I and the pursuer (adversarial disturbance) will be player II and the evader tries with its input to reach the goal while the pursuer tries to steer away from reaching it.
In a differential game setting, it is important to address what information the players know about each other's decisions. To specify our information pattern, first define a strategy for the first player as a map  from the set of disturbances (D) to the set of control inputs (U)  which specifies a disturbance signal for player 2 as a function of the disturbance signal that player 1 chooses.

In problems in which our target set is a reach set, we assume that the Player 1 uses only non-anticipative strategies that are defined in this way:

%(rewrite the formula in this way: alpha : D→U | d1(r) = d2(r) for almost every r belonging to [t,s], then α[d1](r) =α[d2](r) for almost every r belongs to [t,s])

What the formula says is that, a map $\alpha : D \rightarrow U$ is a nonanticipative strategy if  for any $s \geq 0$, for any $d_1(\cdot)$ and $d_2(\cdot)$ belonging to $D$ such that $d_1(\cdot)$ and $d_2(\cdot)$ coincide almost everywhere on $[t,s]$, the image $\alpha(d_1(\cdot))$ and $\alpha(d_2(\cdot))$ coincide almost everywhere on $[t,s]$

This restriction means that if player 1 cannot distinguish between input signals $ \alpha (d_1( \cdot )) $ and $ \alpha (d_2( \cdot ) )$ of player 2 until after time $s$, then player 1 cannot respond differently $( \alpha [d_1](r) = \alpha [ d_2 ](r))$ to those signals until after time $s$. Or in other words, player 1 cannot respond differently to two different player 2 disturbances until they become different.

The aim for this problem is based on a two-person-zero-sum differential game. Zero-sum game is a mathematical representation in game theory of a situation which involves two sides, where the result is an advantage for one side and a loss for the other. If the total gains of the participants are added up, and the total losses are subtracted, they will sum to zero.
In the context of reachability analysis our aim is to reach the goal by finding the control input (Player 1) that minimizes the distance from the reach set while the disturbance  (Player 2) at the same time tries to maximize its action to steer the trajectory away from the set. We can translate this as an optimization problem in which we want to optimize a cost function (that depends on the state, control input and disturbance) of the final state and a running cost that can be seen as a reward accumulated over system trajectories. 
It is possible to formalize what has been said above in this way: let $J_t(x,a(-),b(-))$ denote the cost accumulated during horizon $[i ,f ]$ (in Backward Reachable Set the set interval is $[t,0]$), when Player 1 and Player 2 play control $u(-)$ and $d(-)$ respectively. $J_t(-)$ can be expressed as:

%(CAMBIARE FORMULA CON NOTAZIONI CORRETTE) 

In the zero-sum setting, given this cost function, for the discussion held above, the aim of the game is, for Player 1, to minimize this function, while for Player 2 the aim is to maximize it.
The solution of this problem is a binary solution, this means that given our problem formulation we can say if we avoid or not the set considered; or in other words the outcome of the game says if our control input (the evader) wins or not. This kind of differential game problem is also called game of kind. This problem is formulated in this way in order to compute correctly our BRS. Infact, the computation of the Backward Reachable Set is based on the solution of a game of kind. However, our aim is to find what are the control inputs such that we can reach the set; or in other words, considering the pursuit-evasion game, we don't want to know if the evader (our control input) wins or loses but we want to understand which are the control inputs such that we can win the pursuit-evasion game. So we want to pass from a game of kind in which the outcome is a binary value {Win = 1, Loss = 0} for Player 1 to a game of degree in which the outcome is a value in the real space for Player 1 that can give us information about the final result of the game. A solution to do this transformation is the level set method that will be discussed in section 2.5.  
The BRS, as said in previous section, comes from the solution of a differential game; more precisely, the lower value function V(t,x) (see “Level Set Method” section) is the viscosity solution of a Hamilton-Jacobi-Isaacs (HJI) partial differential equation (PDE) whose the concepts are explained better in the next sections. 

\subsection{Hamilton-Jacobi Equation}					
In physics, the Hamilton-Jacobi equation is an alternative formulation of classical mechanics. It is a first-order nonlinear partial differential equation of the form $H(x,u_x(x,\alpha,t),t)+u_t(x,\alpha,t)=K(\alpha,t)$ with independent variables $(x,t)\in \mathbb{R}^n \times \mathbb{R}$ and parameters $\alpha \in \mathbb{R}^n$. It has wide applications in many scientific fields like mechanics. Its solutions determine infinite families of solutions of Hamilton's ordinary differential equations, which are the equations of motion of a mechanical system. In our case, the family of solutions that come from the computation of the HJI PDE and the variational inequality (see Theorems 1 and 2 in “Problem Formulation”) is the viscosity solution. 

\subsection{Viscosity Solution}
%ESEMPIO WIKIPEDIA
Viscosity solution is a concept introduced by M.Crandall and P. Lions in 1983; it is a notion of solution that allows it to be, for example, nowhere differentiable but for which strong uniqueness theorems, stability theorems and general existence theorems are all valid. It is a generalization of the solution to a partial differential equation (PDE). It has been found that the viscosity solution is that kind of solution to use in many applications of PDE's, including for example first order equations arising in dynamic programming (the Hamilton–Jacobi–Bellman equation) or differential games (the Hamilton–Jacobi–Isaacs equation). This means that, given the classical concept of PDE 
% (0)
under the viscosity solution concept, a certain variable u does not need to be everywhere differentiable. There may be points where Du does not exist and yet u satisfies the equation in an appropriate generalized sense.
Taking the main concepts of viscosity solutions from M. Crandall, L.C Evans and P.L Lions, (let us first formulate the definition of viscosity solutions in the form we think is the most appealing. We begin by recalling that a function u from 0 into R is said to be differentiable at $y0$ belonging to O  and that $Du(y0) = p0$ belonging to $R^m$, if we have 


%(1)

Here a dot b is the Euclidean scalar product of a and b. and $g(y) = o(|y — y_0 |)$ means
. 
%(1) is the conjunction of the two following relations):

let u be a function from O into R and let y0 belong to O.  The superdifferential and subdifferential of u at $y_0$, denoted, respectively, by $D^+u(y\_0)$ and $D^-u(y\_0)$ are the set of points for which, respectively, the following two inequalities hold.:

 %(2)
and
 %(3)

Given these concepts it is possible to define what is a viscosity solution mathematically. 
If $D^+u(y\_0)$ and $D^-u(y\_0)$ are nonempty at some x and u is differentiate at x, a viscosity solution of (0) is a function u belonging to C(O) satisfying the two following conditions:
%(4)


\subsection{Level Set Method}
As mentioned before, in order to compute the BRS is necessary to solve a game of kind where the outcome is boolean: the system state either reaches the target set or not. Level Set Method can be used to translate this game into a game of degree, where players share an objective function to optimize. The basic idea of this approach is to encode the boolean outcome through a quantitative function and compare its value at the end of the game to a threshold value, usually zero, to determine whether or not the system reached the target set.
The first step is to define a Lipschitz function $g(x)$, where $x$ represents the system state, such that the target set $R$ corresponds to the zero sublevel set of $g(x)$, that is, $x\in R \Leftrightarrow g(x) \leq 0$. We indicated the target set with $R$ (reach) since from now on we suppose that the set contains goal states, namely states to reach. Now we can define the cost function of the game $J(\cdot)$, we are not interested in any kind of running cost, therefore we consider only the value of $g(x)$ at the end of a game in which $t \in [\tau_i, \tau_f]$:

\begin{equation}
\label{eq:j_level_set}
    J(x, t, u(\cdot), d(\cdot)) = g(x(\tau_f))
\end{equation}
					
The lower value of the game is given by the following value function $V(x,t)$ in which the control $u$ tries to minimize and the disturbance $d$ to maximize the cost $J(\cdot)$.
We assume that the player that wants to reach the target set $R$, namely the control input $u$ (Player 1), is restricted to use a non-anticipative strategies $\gamma[d](t)$ and we indicates the class of strategies admissible in a time interval $[\tau_i, \tau_f]$ as $\Gamma_{[\tau_i, \tau_f]}$.

\begin{equation}
\begin{split}
    V(x, t) 
    & = \inf_{\gamma(\cdot) \in \Gamma(\cdot) } \sup_{d(\cdot)} J(x, t, \gamma(\cdot), d(\cdot))    \\
    & = \inf_{\gamma(\cdot) \in \Gamma(\cdot) } \sup_{d(\cdot)} g(x(\tau_f))
\end{split}
\end{equation}

In practical scenarios, along the trajectory of a dynamical system there may be both goals to reach and obstacles to avoid. The goals to reach can be represented by the target set $R$ as previously done, the set of states to avoid instead, can be defined with another set $A$ (avoid) that contains all the system state $x$ that corresponds to an object collision, this new kind of set can be defined using a function $h(x)$ similar to $g(x)$. Formally: consider the sets $R$, $A$ related respectively to the level sets of two Lipschitz continuous and bounded functions $g: \mathbb{R}^n \rightarrow \mathbb{R}$, $h: \mathbb{R}^n \rightarrow \mathbb{R}$, then the two sets can be characterized as:

\begin{equation} 
\label{R_A}
R = \left\{ x \in \mathbb{R}^n | g(x) \leq 0 \right\} \, \textrm{and} \, A = \left\{x \in \mathbb{R}^n | h(x) > 0 \right\}
\end{equation}

The most common choice for the function $g(x)$ and $h(x)$ is to use the distance between the state $x$ and the set of interested, namely:

\begin{equation}
\label{g}
    g(x) =
\left\{
	\begin{array}{ll}
		-d(x, R^c)  & \mbox{if } x \in R \\
		d(x, R) & \mbox{if } x \in R^c
	\end{array}
\right.
\end{equation}

\begin{equation}
\label{h}
    h(x) =
\left\{
	\begin{array}{ll}
		d(x, A^c)  & \mbox{if } x \in A \\
		-d(x, A) & \mbox{if } x \in A^c
	\end{array}
\right.
\end{equation}

Since $g(x)$, $h(x)$ must be bounded, we will see later why, we can introduce two constants $C_g$ $C_h$ to impose a saturation to the distance functions, or alternatively, we can use the arctangent of the signed distance, in this way the resulting functions are bounded and also globally Lipschtz \cite{reach_avoid_no_dist}. 
In the next section we will see how the value function $V(\cdot)$ is formulated when we have both a reach $R$ and an avoid $A$ set, and most importantly how it can be solved in order to calculate the BRS. In the following sections we will refer to the BRS as a reach-avoid set (RAS) to highlight the fact that there is both a set to reach and one to avoid.