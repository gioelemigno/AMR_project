In this section we will see how all the previous theoretical concepts can be applied to solve a reachability problem, in which the system state has to reach a desired set $R$ while remains in the constraints set $K$ that represents the complementary of the set of states $A$ that correspond to a collision between the system and an obstacle in the real world.

Given the previous specifications, we can define two different kinds of reachability problems. In the first one we are interested in reaching safely $R$ exactly at the end of the game $(s=T)$, in the second instead, the system can reach safely $R$ at any $s$ inside the time horizon $[t, T]$. In the following we will focus our attention only on this last one.

Consider the system dynamics (\ref{ode}), the two functions $g(\cdot)$, $h(\cdot)$ defined in (\ref{g})(\ref{h}) and used to represent the target set $R$ and the constraint set $K$ respectively. As said before, under these conditions, the system dynamics admits a unique trajectory $x(s)$ from an initial state $x$ at time $t$ under inputs $u(\cdot)$ and $d(\cdot)$. We denote this solution as:
\[
    \phi(s; x, t, u(\cdot), d(\cdot)) : [t, T] \rightarrow \mathbb{R}^n
\]

\subsection{Payoff Function}
We have already seen the payoff function of a reachability problem in which there is only a set to reach (\ref{eq:j_level_set}), now we have to consider also the constraints set $K$ and to do that we can use the following cost function \cite{new_paper}:
\begin{equation}
    \label{j_ras}
    J(x, t, u(\cdot), d(\cdot)) =  
        \min_{\tau \in [t, T]}
        \left\{
            \mathcal{J}(\tau, x, t, u(\cdot), d(\cdot))
        \right\}
\end{equation}
\begin{equation}
    \label{jj_ras}
    \mathcal{J}(\tau, x, t, u(\cdot), d(\cdot)) =  
        \max
        \left\{
            g(\mathcal{X}(\tau), \tau), \max_{r \in [t, \tau]}h(\mathcal{X}(\tau), r)            
        \right\}
\end{equation}
Where: 
\[\mathcal{X}(\tau)=\phi(\tau; x, t, u(\cdot), d(\cdot))\]

The $J(\cdot)$ function is used to evaluate the game and therefore determines if Player 1 ($u(\cdot)$) won or lost. The expression (\ref{j_ras}) considers the value of another function $\mathcal{J}(\cdot)$ for all time $\tau \in [t, T]$ during the game. For each instant $\tau$, $\mathcal{J}(\cdot)$ takes the maximum between two quantities, the first one uses $g(\cdot)$ to determine if the current system state is inside the reach set $R$ and the second instead, uses $h(\cdot)$ to check whether or not the state had ever left the constraints set $K$ so far, namely on time interval $[t, \tau]$. The maximum value of $h(\cdot)$ is taken in order to keep in mind a previous collision before $\tau$, indeed we recall that $(x,s) \in K \Leftrightarrow h(x,s) \leq 0$, therefore a positive value of $h(\cdot)$ indicates an exit from $K$ (obstacle collision).
So, for a given $\tau \in [t, T]$, we have $\mathcal{J} \leq 0$ if and only if, the system trajectory started at time $t$ with initial state $x$, reaches the target $R$ at time $\tau$ without ever having collided with an obstacle on $[t, \tau]$, if this situation takes place for any $\tau \in [t, T]$ then Player 1 wins. For that reason, $J(\cdot)$ takes the minimum time $\tau$, in this way the control input $u(\cdot)$ can win at any moment during the game. It is important to highlight that $J(\cdot)$ does not take into account any collision after the system reached the target set $R$. 

Once defined the cost function of the game, $V^-(x,t)$ and $V^+(x,t)$ are defined in the same way of (\ref{lower_value_game}) (\ref{upper_value_game}) respectively.

\subsection{Definition Reach-Avoid Set}
We are finally ready to define formally the RAS. As said before, we assume $u(\cdot)$ tries to minimize the distance of the system state to $R$, and $d(\cdot)$ tries to do the opposite, potentially also bringing the state outside the constraints set $K=A^c$. In order to consider the worst possible case, we give the strategic advantage to the disturbance, in this way the outcome of the game is given by $V^+(x,t)$ and using it we can compute $RAS^+$. For completeness, we also report the definition of $RAS^-$ namely the reach-avoid set computed through the lower value of the game $V^-(x,t)$.

Given an information pattern, we define the reach-avoid set as the set of point $(x,t)$ for which the system trajectory $\phi(\cdot)$, starting at time $t$ with initial state $x$ and both players acting optimally, reaches the target set $R$ at some instant $\tau \in [t, T]$ while remaining inside the constraints set $K$ for all $s \in [t, \tau]$. We indicate with $\mathcal{R}_s$, $\mathcal{K}_s$ the target set $R$ and the constraints set $K$ at time $s$ respectively.

When the strategic advantage is given to the player that wants to maximize the outcome ($d(\cdot)$), we indicate the reach-avoid set with $RAS^+$ that is formally defined as \cite{new_paper}:
\begin{multline}
    \label{ras_p}
    RAS^+ = 
    \left\{
        (x,t) \in \mathbb{R}^n \times [0,T] \,|\, \exists u^*(\cdot) \in \mathcal{U}_{[0, T]},
    \right.\\
    \left.
          \forall \delta(\cdot) \in \Delta_{[0, T]}, \exists \tau \in [t, T], \phi(\tau; x, t, u^*(\cdot), \delta(\cdot)) \in \mathcal{R}_\tau \quad \wedge \quad       
    \right.\\
    \left.
        \forall s \in [t, \tau], \phi(s; x, t, u^*(\cdot), \delta(\cdot)) \in \mathcal{K}_s
    \right\}
\end{multline}

Similarly, when the player that tries to minimize uses a nonanticipative strategy:
\begin{multline}
    \label{ras_m}
    RAS^- = 
    \left\{
        (x,t) \in \mathbb{R}^n \times [0,T] \,|\, \exists \gamma^*(\cdot) \in \Gamma_{[0, T]},
    \right.\\
    \left.
          \forall d(\cdot) \in \mathcal{D}_{[0, T]}, \exists \tau \in [t, T], \phi(\tau; x, t, \gamma^*(\cdot), d(\cdot)) \in \mathcal{R}_\tau \quad \wedge \quad       
    \right.\\
    \left.
        \forall s \in [t, \tau], \phi(s; x, t, \gamma^*(\cdot), d(\cdot)) \in \mathcal{K}_s
    \right\}
\end{multline}
These two formulations of the reach-avoid set are related to the outcome of the game through the following proposition \cite{new_paper}:
\begin{prop}
    \label{ras_p_m_v}
    The reach-avoid set $RAS^\pm$ is given by the zero sublevel set of the game's outcome: 
    \[
        RAS^\pm=
        \left\{
            (x, t) \in \mathbb{R}^n \times [0, T] \,|\, V^\pm(x,t) \leq 0
        \right\}
    \]
\end{prop}
These two reach-avoid sets are related, indeed the reach-avoid set computed when the strategic advantage is given to the disturbance it is a subset of the one computed given the advantage to the control input \cite{new_paper}:
\begin{equation}
    RAS^+ \subseteq RAS^-
\end{equation}
This relation is the reason why we have chosen to give the advantage to the disturbance, in this way we increase the safety margin.

\subsection{Hamilton-Jacobi-Isaacs Equation}
Given an information pattern, the reach-avoid set $RAS^\pm$ is described by the zero sublevel of the game's outcome $V^\pm(x,t)$. This last is the viscosity solution of a specific Hamilton-Jacobi-Isaacs equation \cite{new_paper}:
\begin{theorem}
    Assume $f(\cdot)$ defined as done in (\ref{ode}), $g(x,t)$, $h(x,t)$ globally Lipschitz continuous. Then the value function $V^\pm(x,t)$ is the unique viscosity solution of the following variational inequality in the form of a Hamilton-Jacobi-Isaacs equation:
    \[
        \max
        \left\{
            \mathcal{H}, \Delta h
        \right\} = 0
    \]
    \[
        \mathcal{H} \triangleq \min
        \left\{
            \frac{\partial V^\pm(x,t)}{\partial t} + 
            H^\pm\left(x, \frac{\partial V^\pm(x,t)}{\partial x}, t\right), \Delta g
        \right\} 
    \]
    \[
        \Delta h \triangleq h(x,t) - V^\pm(x,t), \quad \Delta g \triangleq g(x,t) - V^\pm(x,t)
    \]
    \[
        t \in [0, T] \quad x \in \mathbb{R}^n
    \]
    with terminal condition
    \[
        V^\pm(x,T) = \max \left\{ g(x,T), h(x,T) \right\} \quad x \in \mathbb{R}^n
    \]
    The upper and lower Hamiltonians $H^\pm$ are given by:
    \begin{equation}
        H^+(x,p,t) = \min_{u \in U}\max_{d \in D} p^T f(x, u, d)
        \label{h_p}
    \end{equation}

    \begin{equation}
        H^-(x,p,t) = \max_{d \in D}\min_{u \in U} p^T f(x, u, d)
        \label{h_m}
    \end{equation}
        
    %where:
    %\[
    %    p = \nabla V(x(t),y(t),\theta(t),t) = [p_{x},p_{y},p_{\theta }] 
    %\]
    \label{th:vis_sol}
\end{theorem}

The algorithm of the numerical method able to compute the value function $V^\pm(x,t)$ in Th. \ref{th:vis_sol} is described in \cite{new_paper}. Please notice here we use different notations for target and constraints functions.